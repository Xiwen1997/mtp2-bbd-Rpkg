% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/solver_bbd.R
\name{solver_bbd}
\alias{solver_bbd}
\title{Bridge-block decomposition approach for precision matrix estimation under nonnegative partial correlations}
\usage{
solver_bbd(S, Lambda)
}
\arguments{
\item{S}{Sample covariacne matrix}

\item{Lambda}{Regularization coefficient or regularization matrix}
}
\value{
A list containing the following elements:
\item{\code{time}}{Run time cost before algorithm stopped.}
\item{\code{X_est}}{The estimated precision matrix.}
}
\description{
Bridge-block decomposition approach for precision matrix estimation under nonnegative partial correlations
\preformatted{
  minimize     -log det(Theta) + <Theta, S> + sum_{i neq j} Lambda_{ij} |Theta_{ij}|
  subject to   Theta > 0, Theta_{ij} <=0 forall i neq j
}
}
\examples{
library(mtp2bbd)
library(igraph)
p <- 100 # problem dimension
BA_graph <- barabasi.game(p,  directed = FALSE)
adjacency_matrix <- as_adjacency_matrix(BA_graph,  type = c("both"))
max_eig          <- eigen(adjacency_matrix)$values[1]
A                <- 1.05*max_eig*diag(p) - adjacency_matrix
inv_A            <- solve(A)
D                <- diag(sqrt(diag(inv_A)))
Mtrue            <- D \%*\% A \%*\% D
X                <- MASS::mvrnorm(5 * p , mu = rep(0, p), Sigma = solve(Mtrue))
S                <- cov(X)
bbd_res          <- solver_bbd(S, 0.2)

}
\references{
X. Wang, J. Ying, and D. P. Palomar, ‘Learning Large-Scale MTP2 Gaussian Graphical Models via Bridge-Block Decomposition,’ accepted in Neural Information Processing Systems (NeurIPS), New Orleans, LA, USA, Dec. 2023.
}
\author{
Xiwen Wang, Jiaxi Ying, and Daniel P. Palomar
}
